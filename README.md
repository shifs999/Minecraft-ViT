
# Minecraft-ViT

---

* This project is a basic implementation of Vision Transformer (ViT) model trained on Minecraft gameplay images using PyTorch. It uses unsupervised learning techniques, including masked autoencoding, to learn visual representations without labeled data.
* The model encodes and reconstructs masked image patches, capturing the structure and style of Minecraft scenes.




## The file below will generate the output:

```bash
  python ModelTraining.py
```


## Input

![Alt text](https://github.com/user-attachments/assets/a474d057-3dec-4f80-ba5c-1f897f5e899c "Masked Input")

## Output

![Alt text](https://github.com/user-attachments/assets/8b8c973a-0d0f-4390-840e-3cd59142480c "Generated Output")
